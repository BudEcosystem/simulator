{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from GenZ import decode_moddeling, prefill_moddeling, get_configs\n",
    "\n",
    "import pandas as pd\n",
    "from plotnine import *\n",
    "import plotnine as p9\n",
    "import pandas as pd\n",
    "from GenZ.analyse_model import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will reload the imported modules (e.g. get_decode_model_characterstics) every time you execute the jupyter cells, so that you don't need to restart the notebook after updating the source codes.\n",
    "%load_ext autoreload\n",
    "%autoreload 2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abambhaniya3/GenZ/GenZ/LLM_inference/llm_decode.py:62: UserWarning: All params would not fit on chip. System Memory Cap:40.0 GB , Weights : 1819.125 GB, KV Cache:0.0025634765625 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Num ops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Repeat</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GEMM</td>\n",
       "      <td>[((1, 10752, 1), (32256, 10752), (1, 32256, 1))]</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>346.816512</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>330.75</td>\n",
       "      <td>0.030762</td>\n",
       "      <td>330.791016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logit</td>\n",
       "      <td>((1, 84, 1, 128), (1, 84, 1, 128), (1, 84, 1, 1))</td>\n",
       "      <td>0.498054</td>\n",
       "      <td>0.010752</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.020588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logit</td>\n",
       "      <td>((1, 84, 1, 128), (1, 84, 0, 128), (1, 84, 1, 0))</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Attend</td>\n",
       "      <td>((1, 84, 1, 1), (1, 84, 1, 128), (1, 84, 1, 128))</td>\n",
       "      <td>0.498054</td>\n",
       "      <td>0.010752</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>0.020588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Attend</td>\n",
       "      <td>((1, 84, 1, 0), (1, 84, 0, 128), (1, 84, 1, 128))</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>0.010254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GEMM</td>\n",
       "      <td>[((1, 10752, 1), (10752, 10752), (1, 10752, 1))]</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>115.605504</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>110.25</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>110.270508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GEMM</td>\n",
       "      <td>[((1, 10752, 1), (86016, 10752), (1, 86016, 1))]</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>924.844032</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>882.0</td>\n",
       "      <td>0.082031</td>\n",
       "      <td>882.092285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GEMM</td>\n",
       "      <td>[((1, 10752, 0), (602112, 10752), (1, 602112, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GEMM</td>\n",
       "      <td>[((1, 86016, 1), (10752, 86016), (1, 10752, 1))]</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>924.844032</td>\n",
       "      <td>0.082031</td>\n",
       "      <td>882.0</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>882.092285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GEMM</td>\n",
       "      <td>[((1, 602112, 0), (10752, 602112), (1, 10752, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EndRepeat</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Op Type                                          Dimension Op Intensity  \\\n",
       "0      Repeat                                                128            0   \n",
       "1        GEMM   [((1, 10752, 1), (32256, 10752), (1, 32256, 1))]     0.999876   \n",
       "2       Logit  ((1, 84, 1, 128), (1, 84, 1, 128), (1, 84, 1, 1))     0.498054   \n",
       "3       Logit  ((1, 84, 1, 128), (1, 84, 0, 128), (1, 84, 1, 0))          0.0   \n",
       "4      Attend  ((1, 84, 1, 1), (1, 84, 1, 128), (1, 84, 1, 128))     0.498054   \n",
       "5      Attend  ((1, 84, 1, 0), (1, 84, 0, 128), (1, 84, 1, 128))          0.0   \n",
       "6        GEMM   [((1, 10752, 1), (10752, 10752), (1, 10752, 1))]     0.999814   \n",
       "7        GEMM   [((1, 10752, 1), (86016, 10752), (1, 86016, 1))]     0.999895   \n",
       "8        GEMM  [((1, 10752, 0), (602112, 10752), (1, 602112, ...          0.0   \n",
       "9        GEMM   [((1, 86016, 1), (10752, 86016), (1, 10752, 1))]     0.999895   \n",
       "10       GEMM  [((1, 602112, 0), (10752, 602112), (1, 10752, ...          0.0   \n",
       "11  EndRepeat                                                128            0   \n",
       "\n",
       "   Num ops (MFLOP) Input_a (MB) Input_w (MB) Output (MB) Total Data (MB)  \n",
       "0              0.0          0.0          0.0         0.0             0.0  \n",
       "1       346.816512     0.010254       330.75    0.030762      330.791016  \n",
       "2         0.010752     0.010254     0.010254     0.00008        0.020588  \n",
       "3              0.0     0.010254          0.0         0.0        0.010254  \n",
       "4         0.010752      0.00008     0.010254    0.010254        0.020588  \n",
       "5              0.0          0.0          0.0    0.010254        0.010254  \n",
       "6       115.605504     0.010254       110.25    0.010254      110.270508  \n",
       "7       924.844032     0.010254        882.0    0.082031      882.092285  \n",
       "8              0.0          0.0       6174.0         0.0          6174.0  \n",
       "9       924.844032     0.082031        882.0    0.010254      882.092285  \n",
       "10             0.0          0.0       6174.0         0.0          6174.0  \n",
       "11             0.0          0.0          0.0         0.0             0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MACs (MFLOP)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Total Weights (MB)</th>\n",
       "      <th>Unused Weights (MB)</th>\n",
       "      <th>KV Cache (MB)</th>\n",
       "      <th>On-chip Memory Footprint (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>295952.842752</td>\n",
       "      <td>1.862823e+06</td>\n",
       "      <td>1862784.0</td>\n",
       "      <td>12348.0</td>\n",
       "      <td>2.625</td>\n",
       "      <td>6174.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MACs (MFLOP)  Total Data (MB)  Total Weights (MB)  Unused Weights (MB)  \\\n",
       "0  295952.842752     1.862823e+06           1862784.0              12348.0   \n",
       "\n",
       "   KV Cache (MB)  On-chip Memory Footprint (MB)  \n",
       "0          2.625                         6174.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D = get_configs('GPT-4').hidden_size\n",
    "V = 50257\n",
    "model_df, summary_table = decode_moddeling(model = 'gpt-4', batch_size = 1, Bb = 1 , bits='int8',\n",
    "                            input_tokens = 1, output_tokens = 0, model_profilling=True,\n",
    "                            tensor_parallel = 1, pipeline_parallel = 1, debug=True) \n",
    "display(model_df)\n",
    "display(summary_table)\n",
    "# print(f'Model Weights={summary_table['Model Weights (MB)'][0]*2**20/1e12} T')\n",
    "# print(f'Attn Size:{(model_df.loc[0,'Input_w (MB)'] + model_df.loc[5,'Input_w (MB)'])*120*2**20/1e9} B')\n",
    "# print(f'Each MLP Size:{sum(model_df.loc[6:,'Input_w (MB)'])*120*2**20/1e9/16} B')\n",
    "# print(f'FWD pass MLP Size:{sum(model_df.loc[6:,'Input_w (MB)'])*120/1024/16} B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abambhaniya3/GenZ/GenZ/LLM_inference/llm_prefill.py:22: UserWarning: Batch size is divided into micro batches for pipeline parallel, micro batch size:1, consider increasing batch size\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Num ops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Repeat</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GEMM</td>\n",
       "      <td>[((1, 10752, 1024), (4032, 10752), (1, 4032, 1...</td>\n",
       "      <td>379.482353</td>\n",
       "      <td>44392.513536</td>\n",
       "      <td>21.0</td>\n",
       "      <td>82.6875</td>\n",
       "      <td>7.875</td>\n",
       "      <td>111.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logit</td>\n",
       "      <td>((1, 10, 1024, 128), (1, 10, 1024, 128), (1, 1...</td>\n",
       "      <td>51.2</td>\n",
       "      <td>1342.17728</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Attend</td>\n",
       "      <td>((1, 10, 1024, 1024), (1, 10, 1024, 128), (1, ...</td>\n",
       "      <td>51.2</td>\n",
       "      <td>1342.17728</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GEMM</td>\n",
       "      <td>[((1, 1280, 1024), (10752, 1280), (1, 10752, 1...</td>\n",
       "      <td>270.150754</td>\n",
       "      <td>14092.86144</td>\n",
       "      <td>2.5</td>\n",
       "      <td>26.25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>49.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sync</td>\n",
       "      <td>(1, 1024, 10752)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GEMM</td>\n",
       "      <td>[((1, 10752, 128), (86016, 10752), (1, 86016, ...</td>\n",
       "      <td>63.154185</td>\n",
       "      <td>118380.036096</td>\n",
       "      <td>2.625</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1787.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GEMM</td>\n",
       "      <td>[((1, 86016, 128), (10752, 86016), (1, 10752, ...</td>\n",
       "      <td>63.154185</td>\n",
       "      <td>118380.036096</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>2.625</td>\n",
       "      <td>1787.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sync</td>\n",
       "      <td>(1, 1024, 10752)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EndRepeat</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Op Type                                          Dimension Op Intensity  \\\n",
       "0     Repeat                                                128            0   \n",
       "1       GEMM  [((1, 10752, 1024), (4032, 10752), (1, 4032, 1...   379.482353   \n",
       "2      Logit  ((1, 10, 1024, 128), (1, 10, 1024, 128), (1, 1...         51.2   \n",
       "3     Attend  ((1, 10, 1024, 1024), (1, 10, 1024, 128), (1, ...         51.2   \n",
       "4       GEMM  [((1, 1280, 1024), (10752, 1280), (1, 10752, 1...   270.150754   \n",
       "5       Sync                                   (1, 1024, 10752)            0   \n",
       "6       GEMM  [((1, 10752, 128), (86016, 10752), (1, 86016, ...    63.154185   \n",
       "7       GEMM  [((1, 86016, 128), (10752, 86016), (1, 10752, ...    63.154185   \n",
       "8       Sync                                   (1, 1024, 10752)            0   \n",
       "9  EndRepeat                                                128            0   \n",
       "\n",
       "  Num ops (MFLOP) Input_a (MB) Input_w (MB) Output (MB) Total Data (MB)  \n",
       "0             0.0          0.0          0.0         0.0             0.0  \n",
       "1    44392.513536         21.0      82.6875       7.875        111.5625  \n",
       "2      1342.17728          2.5          2.5        20.0            25.0  \n",
       "3      1342.17728         20.0          2.5         2.5            25.0  \n",
       "4     14092.86144          2.5        26.25        21.0           49.75  \n",
       "5             0.0          0.0          0.0         0.0             0.0  \n",
       "6   118380.036096        2.625       1764.0        21.0        1787.625  \n",
       "7   118380.036096         21.0       1764.0       2.625        1787.625  \n",
       "8             0.0          0.0          0.0         0.0             0.0  \n",
       "9             0.0          0.0          0.0         0.0             0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MACs (MFLOP)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Total Weights (MB)</th>\n",
       "      <th>Unused Weights (MB)</th>\n",
       "      <th>KV Cache (MB)</th>\n",
       "      <th>On-chip Memory Footprint (MB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.813501e+07</td>\n",
       "      <td>484680.0</td>\n",
       "      <td>465528.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1787.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MACs (MFLOP)  Total Data (MB)  Total Weights (MB)  Unused Weights (MB)  \\\n",
       "0  3.813501e+07         484680.0            465528.0                  0.0   \n",
       "\n",
       "   KV Cache (MB)  On-chip Memory Footprint (MB)  \n",
       "0          640.0                       1787.625  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in ['gpt-4']:\n",
    "    model_df, summary_table = prefill_moddeling(model = model, batch_size = 1,\n",
    "                            input_tokens = 1024, model_profilling=True,\n",
    "                            tensor_parallel = 8, pipeline_parallel = 16) \n",
    "    print(model)\n",
    "    display(model_df)\n",
    "    display(summary_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abambhaniya3/GenZ/GenZ/LLM_inference/llm_prefill.py:22: UserWarning: Batch size is divided into micro batches for pipeline parallel, micro batch size:1, consider increasing batch size\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Latency': 111.044776197886,\n",
       " 'Throughput': 9.0053763377213,\n",
       " 'Runtime_breakdown': [81.33332687512731,\n",
       "  1.3252982810920122,\n",
       "  28.38615104166667],\n",
       " 'is_offload': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefill_moddeling(model = 'gpt-4', batch_size = 1,\n",
    "                                            input_tokens = 2000,\n",
    "                                            system_name = 'H100_GPU',\n",
    "                                            bits='int8',\n",
    "                                            tensor_parallel = 8, pipeline_parallel = 16, debug=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abambhaniya3/GenZ/GenZ/LLM_inference/llm_decode.py:24: UserWarning: Batch size is divided into micro batches for pipeline parallel, micro batch size:1, consider increasing batch size\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Latency': 18.870783471400443,\n",
       " 'Throughput': 52.99197044550624,\n",
       " 'Runtime_breakdown': [10.110994924906809,\n",
       "  0.27191224441029666,\n",
       "  8.487876302083334],\n",
       " 'is_offload': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_moddeling(model = 'gpt-4', batch_size = 1, Bb = 4 ,\n",
    "                                            input_tokens = 2000, output_tokens = 256, \n",
    "                                            system_name = 'H100_GPU',\n",
    "                                            bits='int8',\n",
    "                                            tensor_parallel = 8, pipeline_parallel = 16, debug=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genz_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
